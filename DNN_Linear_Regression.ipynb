{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dense neural network to perform Linear regression task  "
      ],
      "metadata": {
        "id": "UGYrGmy7Xwcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Atharva Mankame 21BAI1780"
      ],
      "metadata": {
        "id": "k9y9sRzaXwQk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxChR1Rk-umf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9CV13Co_HHM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ca3495f-88cf-4cd4-ec08-6e2afa997347"
      },
      "source": [
        "dataset = pd.read_csv('50_Startups_dataset.csv')\n",
        "dataset"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0  R&D Spend  Administration  Marketing Spend       State  \\\n",
              "0            0  165349.30       136897.90        471784.20    New York   \n",
              "1            1  162597.80       151377.69        443898.63  California   \n",
              "2            2  153441.61       101145.65        407934.64     Florida   \n",
              "3            3  144372.51       118671.95        383199.72    New York   \n",
              "4            4  142107.44        91391.87        366168.52     Florida   \n",
              "5            5  131877.00        99814.81        362861.46    New York   \n",
              "6            6  134615.56       147198.97        127716.92  California   \n",
              "7            7  130298.23       145530.16        323876.78     Florida   \n",
              "8            8  120542.62       148719.05        311613.39    New York   \n",
              "9            9  123334.98       108679.27        304981.72  California   \n",
              "10          10  101913.18       110594.21        229161.05     Florida   \n",
              "11          11  100672.06        91790.71        249744.65  California   \n",
              "12          12   93863.85       127320.48        249839.54     Florida   \n",
              "13          13   91992.49       135495.17        252665.03  California   \n",
              "14          14  119943.34       156547.52        256513.02     Florida   \n",
              "15          15  114523.71       122616.94        261776.33    New York   \n",
              "16          16   78013.21       121597.65        264346.16  California   \n",
              "17          17   94657.26       145077.68        282574.41    New York   \n",
              "18          18   91749.26       114175.89        294919.67     Florida   \n",
              "19          19   86419.80       153514.21             0.10    New York   \n",
              "20          20   76253.96       113867.40        298664.57  California   \n",
              "21          21   78389.57       153773.53        299737.39    New York   \n",
              "22          22   73994.66       122782.85        303319.36     Florida   \n",
              "23          23   67532.63       105751.13        304768.83     Florida   \n",
              "24          24   77044.11        99281.44        140574.91    New York   \n",
              "25          25   64664.81       139553.26        137962.72  California   \n",
              "26          26   75328.97       144136.08        134050.17     Florida   \n",
              "27          27   72107.70       127864.65        353183.91    New York   \n",
              "28          28   66051.62       182645.66        118148.30     Florida   \n",
              "29          29   65605.58       153032.16        107138.48    New York   \n",
              "30          30   61994.58       115641.38         91131.34     Florida   \n",
              "31          31   61136.48       152702.02         88218.33    New York   \n",
              "32          32   63408.96       129219.71         46085.35  California   \n",
              "33          33   55494.05       103057.59        214634.91     Florida   \n",
              "34          34   46426.17       157694.02        210797.77  California   \n",
              "35          35   46014.12        85047.54        205517.74    New York   \n",
              "36          36   28663.86       127056.31        201126.92     Florida   \n",
              "37          37   44070.05        51283.24        197029.52  California   \n",
              "38          38   20229.69        65948.03        185265.20    New York   \n",
              "39          39   38558.61        82982.19        174999.40  California   \n",
              "40          40   28754.43       118546.15        172795.77  California   \n",
              "41          41   27893.02        84710.87        164470.81     Florida   \n",
              "42          42   23641.03        96189.73        148001.21  California   \n",
              "43          43   15505.83       127382.40         35534.27    New York   \n",
              "44          44   22177.84       154806.24         28334.82  California   \n",
              "45          45    1000.33       124153.14          1904.03    New York   \n",
              "46          46    1315.56       115816.31        297114.56     Florida   \n",
              "47          47       0.10       135427.02             0.10  California   \n",
              "48          48     542.15        51743.25             0.10    New York   \n",
              "49          49       0.10       116983.90         45173.16  California   \n",
              "\n",
              "       Profit  \n",
              "0   192261.93  \n",
              "1   191792.16  \n",
              "2   191050.49  \n",
              "3   182902.09  \n",
              "4   166188.04  \n",
              "5   156991.22  \n",
              "6   156122.61  \n",
              "7   155752.70  \n",
              "8   152211.87  \n",
              "9   149760.06  \n",
              "10  146122.05  \n",
              "11  144259.50  \n",
              "12  141585.62  \n",
              "13  134307.45  \n",
              "14  132602.75  \n",
              "15  129917.14  \n",
              "16  126993.03  \n",
              "17  125370.47  \n",
              "18  124267.00  \n",
              "19  122776.96  \n",
              "20  118474.13  \n",
              "21  111313.12  \n",
              "22  110352.35  \n",
              "23  108734.09  \n",
              "24  108552.14  \n",
              "25  107404.44  \n",
              "26  105733.64  \n",
              "27  105008.41  \n",
              "28  103282.48  \n",
              "29  101004.74  \n",
              "30   99937.69  \n",
              "31   97483.66  \n",
              "32   97427.94  \n",
              "33   96779.02  \n",
              "34   96712.90  \n",
              "35   96479.61  \n",
              "36   90708.29  \n",
              "37   89949.24  \n",
              "38   81229.16  \n",
              "39   81005.86  \n",
              "40   78240.01  \n",
              "41   77798.93  \n",
              "42   71498.59  \n",
              "43   69759.08  \n",
              "44   65200.43  \n",
              "45   64926.18  \n",
              "46   49490.85  \n",
              "47   42559.83  \n",
              "48   35673.51  \n",
              "49   14681.50  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4285eab0-c2b3-4fe1-8d6f-174e5e222300\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>State</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>165349.30</td>\n",
              "      <td>136897.90</td>\n",
              "      <td>471784.20</td>\n",
              "      <td>New York</td>\n",
              "      <td>192261.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>162597.80</td>\n",
              "      <td>151377.69</td>\n",
              "      <td>443898.63</td>\n",
              "      <td>California</td>\n",
              "      <td>191792.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>153441.61</td>\n",
              "      <td>101145.65</td>\n",
              "      <td>407934.64</td>\n",
              "      <td>Florida</td>\n",
              "      <td>191050.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>144372.51</td>\n",
              "      <td>118671.95</td>\n",
              "      <td>383199.72</td>\n",
              "      <td>New York</td>\n",
              "      <td>182902.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>142107.44</td>\n",
              "      <td>91391.87</td>\n",
              "      <td>366168.52</td>\n",
              "      <td>Florida</td>\n",
              "      <td>166188.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>131877.00</td>\n",
              "      <td>99814.81</td>\n",
              "      <td>362861.46</td>\n",
              "      <td>New York</td>\n",
              "      <td>156991.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>134615.56</td>\n",
              "      <td>147198.97</td>\n",
              "      <td>127716.92</td>\n",
              "      <td>California</td>\n",
              "      <td>156122.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>130298.23</td>\n",
              "      <td>145530.16</td>\n",
              "      <td>323876.78</td>\n",
              "      <td>Florida</td>\n",
              "      <td>155752.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>120542.62</td>\n",
              "      <td>148719.05</td>\n",
              "      <td>311613.39</td>\n",
              "      <td>New York</td>\n",
              "      <td>152211.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>123334.98</td>\n",
              "      <td>108679.27</td>\n",
              "      <td>304981.72</td>\n",
              "      <td>California</td>\n",
              "      <td>149760.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>101913.18</td>\n",
              "      <td>110594.21</td>\n",
              "      <td>229161.05</td>\n",
              "      <td>Florida</td>\n",
              "      <td>146122.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>100672.06</td>\n",
              "      <td>91790.71</td>\n",
              "      <td>249744.65</td>\n",
              "      <td>California</td>\n",
              "      <td>144259.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>93863.85</td>\n",
              "      <td>127320.48</td>\n",
              "      <td>249839.54</td>\n",
              "      <td>Florida</td>\n",
              "      <td>141585.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>91992.49</td>\n",
              "      <td>135495.17</td>\n",
              "      <td>252665.03</td>\n",
              "      <td>California</td>\n",
              "      <td>134307.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>119943.34</td>\n",
              "      <td>156547.52</td>\n",
              "      <td>256513.02</td>\n",
              "      <td>Florida</td>\n",
              "      <td>132602.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>114523.71</td>\n",
              "      <td>122616.94</td>\n",
              "      <td>261776.33</td>\n",
              "      <td>New York</td>\n",
              "      <td>129917.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>78013.21</td>\n",
              "      <td>121597.65</td>\n",
              "      <td>264346.16</td>\n",
              "      <td>California</td>\n",
              "      <td>126993.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>94657.26</td>\n",
              "      <td>145077.68</td>\n",
              "      <td>282574.41</td>\n",
              "      <td>New York</td>\n",
              "      <td>125370.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>91749.26</td>\n",
              "      <td>114175.89</td>\n",
              "      <td>294919.67</td>\n",
              "      <td>Florida</td>\n",
              "      <td>124267.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>86419.80</td>\n",
              "      <td>153514.21</td>\n",
              "      <td>0.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>122776.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>76253.96</td>\n",
              "      <td>113867.40</td>\n",
              "      <td>298664.57</td>\n",
              "      <td>California</td>\n",
              "      <td>118474.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>78389.57</td>\n",
              "      <td>153773.53</td>\n",
              "      <td>299737.39</td>\n",
              "      <td>New York</td>\n",
              "      <td>111313.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>73994.66</td>\n",
              "      <td>122782.85</td>\n",
              "      <td>303319.36</td>\n",
              "      <td>Florida</td>\n",
              "      <td>110352.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>67532.63</td>\n",
              "      <td>105751.13</td>\n",
              "      <td>304768.83</td>\n",
              "      <td>Florida</td>\n",
              "      <td>108734.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>77044.11</td>\n",
              "      <td>99281.44</td>\n",
              "      <td>140574.91</td>\n",
              "      <td>New York</td>\n",
              "      <td>108552.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>64664.81</td>\n",
              "      <td>139553.26</td>\n",
              "      <td>137962.72</td>\n",
              "      <td>California</td>\n",
              "      <td>107404.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>75328.97</td>\n",
              "      <td>144136.08</td>\n",
              "      <td>134050.17</td>\n",
              "      <td>Florida</td>\n",
              "      <td>105733.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>72107.70</td>\n",
              "      <td>127864.65</td>\n",
              "      <td>353183.91</td>\n",
              "      <td>New York</td>\n",
              "      <td>105008.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>66051.62</td>\n",
              "      <td>182645.66</td>\n",
              "      <td>118148.30</td>\n",
              "      <td>Florida</td>\n",
              "      <td>103282.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>65605.58</td>\n",
              "      <td>153032.16</td>\n",
              "      <td>107138.48</td>\n",
              "      <td>New York</td>\n",
              "      <td>101004.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>61994.58</td>\n",
              "      <td>115641.38</td>\n",
              "      <td>91131.34</td>\n",
              "      <td>Florida</td>\n",
              "      <td>99937.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>61136.48</td>\n",
              "      <td>152702.02</td>\n",
              "      <td>88218.33</td>\n",
              "      <td>New York</td>\n",
              "      <td>97483.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>63408.96</td>\n",
              "      <td>129219.71</td>\n",
              "      <td>46085.35</td>\n",
              "      <td>California</td>\n",
              "      <td>97427.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>55494.05</td>\n",
              "      <td>103057.59</td>\n",
              "      <td>214634.91</td>\n",
              "      <td>Florida</td>\n",
              "      <td>96779.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>46426.17</td>\n",
              "      <td>157694.02</td>\n",
              "      <td>210797.77</td>\n",
              "      <td>California</td>\n",
              "      <td>96712.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>46014.12</td>\n",
              "      <td>85047.54</td>\n",
              "      <td>205517.74</td>\n",
              "      <td>New York</td>\n",
              "      <td>96479.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>28663.86</td>\n",
              "      <td>127056.31</td>\n",
              "      <td>201126.92</td>\n",
              "      <td>Florida</td>\n",
              "      <td>90708.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>44070.05</td>\n",
              "      <td>51283.24</td>\n",
              "      <td>197029.52</td>\n",
              "      <td>California</td>\n",
              "      <td>89949.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>20229.69</td>\n",
              "      <td>65948.03</td>\n",
              "      <td>185265.20</td>\n",
              "      <td>New York</td>\n",
              "      <td>81229.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>38558.61</td>\n",
              "      <td>82982.19</td>\n",
              "      <td>174999.40</td>\n",
              "      <td>California</td>\n",
              "      <td>81005.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>28754.43</td>\n",
              "      <td>118546.15</td>\n",
              "      <td>172795.77</td>\n",
              "      <td>California</td>\n",
              "      <td>78240.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>27893.02</td>\n",
              "      <td>84710.87</td>\n",
              "      <td>164470.81</td>\n",
              "      <td>Florida</td>\n",
              "      <td>77798.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>23641.03</td>\n",
              "      <td>96189.73</td>\n",
              "      <td>148001.21</td>\n",
              "      <td>California</td>\n",
              "      <td>71498.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>15505.83</td>\n",
              "      <td>127382.40</td>\n",
              "      <td>35534.27</td>\n",
              "      <td>New York</td>\n",
              "      <td>69759.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>22177.84</td>\n",
              "      <td>154806.24</td>\n",
              "      <td>28334.82</td>\n",
              "      <td>California</td>\n",
              "      <td>65200.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>45</td>\n",
              "      <td>1000.33</td>\n",
              "      <td>124153.14</td>\n",
              "      <td>1904.03</td>\n",
              "      <td>New York</td>\n",
              "      <td>64926.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>1315.56</td>\n",
              "      <td>115816.31</td>\n",
              "      <td>297114.56</td>\n",
              "      <td>Florida</td>\n",
              "      <td>49490.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>0.10</td>\n",
              "      <td>135427.02</td>\n",
              "      <td>0.10</td>\n",
              "      <td>California</td>\n",
              "      <td>42559.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>542.15</td>\n",
              "      <td>51743.25</td>\n",
              "      <td>0.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>35673.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>0.10</td>\n",
              "      <td>116983.90</td>\n",
              "      <td>45173.16</td>\n",
              "      <td>California</td>\n",
              "      <td>14681.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4285eab0-c2b3-4fe1-8d6f-174e5e222300')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4285eab0-c2b3-4fe1-8d6f-174e5e222300 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4285eab0-c2b3-4fe1-8d6f-174e5e222300');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02db218a-8e0f-4ff9-8534-961db321db09\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02db218a-8e0f-4ff9-8534-961db321db09')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02db218a-8e0f-4ff9-8534-961db321db09 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_74d76d05-31be-4dd9-ad69-5c43be27278d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_74d76d05-31be-4dd9-ad69-5c43be27278d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "dataset['State'] = le.fit_transform(dataset['State'])"
      ],
      "metadata": {
        "id": "z7FPHH4I-ip2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "naXx0bbB-VoA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "SffN7GdT3tUh",
        "outputId": "3877e2f5-bfb4-4279-df7b-e8cb677552a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0000000e+00, 1.6534930e+05, 1.3689790e+05, 4.7178420e+05,\n",
              "        2.0000000e+00],\n",
              "       [1.0000000e+00, 1.6259780e+05, 1.5137769e+05, 4.4389863e+05,\n",
              "        0.0000000e+00],\n",
              "       [2.0000000e+00, 1.5344161e+05, 1.0114565e+05, 4.0793464e+05,\n",
              "        1.0000000e+00],\n",
              "       [3.0000000e+00, 1.4437251e+05, 1.1867195e+05, 3.8319972e+05,\n",
              "        2.0000000e+00],\n",
              "       [4.0000000e+00, 1.4210744e+05, 9.1391870e+04, 3.6616852e+05,\n",
              "        1.0000000e+00],\n",
              "       [5.0000000e+00, 1.3187700e+05, 9.9814810e+04, 3.6286146e+05,\n",
              "        2.0000000e+00],\n",
              "       [6.0000000e+00, 1.3461556e+05, 1.4719897e+05, 1.2771692e+05,\n",
              "        0.0000000e+00],\n",
              "       [7.0000000e+00, 1.3029823e+05, 1.4553016e+05, 3.2387678e+05,\n",
              "        1.0000000e+00],\n",
              "       [8.0000000e+00, 1.2054262e+05, 1.4871905e+05, 3.1161339e+05,\n",
              "        2.0000000e+00],\n",
              "       [9.0000000e+00, 1.2333498e+05, 1.0867927e+05, 3.0498172e+05,\n",
              "        0.0000000e+00],\n",
              "       [1.0000000e+01, 1.0191318e+05, 1.1059421e+05, 2.2916105e+05,\n",
              "        1.0000000e+00],\n",
              "       [1.1000000e+01, 1.0067206e+05, 9.1790710e+04, 2.4974465e+05,\n",
              "        0.0000000e+00],\n",
              "       [1.2000000e+01, 9.3863850e+04, 1.2732048e+05, 2.4983954e+05,\n",
              "        1.0000000e+00],\n",
              "       [1.3000000e+01, 9.1992490e+04, 1.3549517e+05, 2.5266503e+05,\n",
              "        0.0000000e+00],\n",
              "       [1.4000000e+01, 1.1994334e+05, 1.5654752e+05, 2.5651302e+05,\n",
              "        1.0000000e+00],\n",
              "       [1.5000000e+01, 1.1452371e+05, 1.2261694e+05, 2.6177633e+05,\n",
              "        2.0000000e+00],\n",
              "       [1.6000000e+01, 7.8013210e+04, 1.2159765e+05, 2.6434616e+05,\n",
              "        0.0000000e+00],\n",
              "       [1.7000000e+01, 9.4657260e+04, 1.4507768e+05, 2.8257441e+05,\n",
              "        2.0000000e+00],\n",
              "       [1.8000000e+01, 9.1749260e+04, 1.1417589e+05, 2.9491967e+05,\n",
              "        1.0000000e+00],\n",
              "       [1.9000000e+01, 8.6419800e+04, 1.5351421e+05, 1.0000000e-01,\n",
              "        2.0000000e+00],\n",
              "       [2.0000000e+01, 7.6253960e+04, 1.1386740e+05, 2.9866457e+05,\n",
              "        0.0000000e+00],\n",
              "       [2.1000000e+01, 7.8389570e+04, 1.5377353e+05, 2.9973739e+05,\n",
              "        2.0000000e+00],\n",
              "       [2.2000000e+01, 7.3994660e+04, 1.2278285e+05, 3.0331936e+05,\n",
              "        1.0000000e+00],\n",
              "       [2.3000000e+01, 6.7532630e+04, 1.0575113e+05, 3.0476883e+05,\n",
              "        1.0000000e+00],\n",
              "       [2.4000000e+01, 7.7044110e+04, 9.9281440e+04, 1.4057491e+05,\n",
              "        2.0000000e+00],\n",
              "       [2.5000000e+01, 6.4664810e+04, 1.3955326e+05, 1.3796272e+05,\n",
              "        0.0000000e+00],\n",
              "       [2.6000000e+01, 7.5328970e+04, 1.4413608e+05, 1.3405017e+05,\n",
              "        1.0000000e+00],\n",
              "       [2.7000000e+01, 7.2107700e+04, 1.2786465e+05, 3.5318391e+05,\n",
              "        2.0000000e+00],\n",
              "       [2.8000000e+01, 6.6051620e+04, 1.8264566e+05, 1.1814830e+05,\n",
              "        1.0000000e+00],\n",
              "       [2.9000000e+01, 6.5605580e+04, 1.5303216e+05, 1.0713848e+05,\n",
              "        2.0000000e+00],\n",
              "       [3.0000000e+01, 6.1994580e+04, 1.1564138e+05, 9.1131340e+04,\n",
              "        1.0000000e+00],\n",
              "       [3.1000000e+01, 6.1136480e+04, 1.5270202e+05, 8.8218330e+04,\n",
              "        2.0000000e+00],\n",
              "       [3.2000000e+01, 6.3408960e+04, 1.2921971e+05, 4.6085350e+04,\n",
              "        0.0000000e+00],\n",
              "       [3.3000000e+01, 5.5494050e+04, 1.0305759e+05, 2.1463491e+05,\n",
              "        1.0000000e+00],\n",
              "       [3.4000000e+01, 4.6426170e+04, 1.5769402e+05, 2.1079777e+05,\n",
              "        0.0000000e+00],\n",
              "       [3.5000000e+01, 4.6014120e+04, 8.5047540e+04, 2.0551774e+05,\n",
              "        2.0000000e+00],\n",
              "       [3.6000000e+01, 2.8663860e+04, 1.2705631e+05, 2.0112692e+05,\n",
              "        1.0000000e+00],\n",
              "       [3.7000000e+01, 4.4070050e+04, 5.1283240e+04, 1.9702952e+05,\n",
              "        0.0000000e+00],\n",
              "       [3.8000000e+01, 2.0229690e+04, 6.5948030e+04, 1.8526520e+05,\n",
              "        2.0000000e+00],\n",
              "       [3.9000000e+01, 3.8558610e+04, 8.2982190e+04, 1.7499940e+05,\n",
              "        0.0000000e+00],\n",
              "       [4.0000000e+01, 2.8754430e+04, 1.1854615e+05, 1.7279577e+05,\n",
              "        0.0000000e+00],\n",
              "       [4.1000000e+01, 2.7893020e+04, 8.4710870e+04, 1.6447081e+05,\n",
              "        1.0000000e+00],\n",
              "       [4.2000000e+01, 2.3641030e+04, 9.6189730e+04, 1.4800121e+05,\n",
              "        0.0000000e+00],\n",
              "       [4.3000000e+01, 1.5505830e+04, 1.2738240e+05, 3.5534270e+04,\n",
              "        2.0000000e+00],\n",
              "       [4.4000000e+01, 2.2177840e+04, 1.5480624e+05, 2.8334820e+04,\n",
              "        0.0000000e+00],\n",
              "       [4.5000000e+01, 1.0003300e+03, 1.2415314e+05, 1.9040300e+03,\n",
              "        2.0000000e+00],\n",
              "       [4.6000000e+01, 1.3155600e+03, 1.1581631e+05, 2.9711456e+05,\n",
              "        1.0000000e+00],\n",
              "       [4.7000000e+01, 1.0000000e-01, 1.3542702e+05, 1.0000000e-01,\n",
              "        0.0000000e+00],\n",
              "       [4.8000000e+01, 5.4215000e+02, 5.1743250e+04, 1.0000000e-01,\n",
              "        2.0000000e+00],\n",
              "       [4.9000000e+01, 1.0000000e-01, 1.1698390e+05, 4.5173160e+04,\n",
              "        0.0000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "z7ahTCR63tcY",
        "outputId": "f503a995-c3be-4fff-a34d-842a3506c34c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([192261.93, 191792.16, 191050.49, 182902.09, 166188.04, 156991.22,\n",
              "       156122.61, 155752.7 , 152211.87, 149760.06, 146122.05, 144259.5 ,\n",
              "       141585.62, 134307.45, 132602.75, 129917.14, 126993.03, 125370.47,\n",
              "       124267.  , 122776.96, 118474.13, 111313.12, 110352.35, 108734.09,\n",
              "       108552.14, 107404.44, 105733.64, 105008.41, 103282.48, 101004.74,\n",
              "        99937.69,  97483.66,  97427.94,  96779.02,  96712.9 ,  96479.61,\n",
              "        90708.29,  89949.24,  81229.16,  81005.86,  78240.01,  77798.93,\n",
              "        71498.59,  69759.08,  65200.43,  64926.18,  49490.85,  42559.83,\n",
              "        35673.51,  14681.5 ])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5edeb2r_agx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Hd97Ls__Nz"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksO_Vv40AHix"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "# ann.add(tf.keras.layers.Dense(units=1))\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pesgbWlCAtB4"
      },
      "source": [
        "ann.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mean_absolute_error'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_vV-tiiA5zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0840afb8-9fcc-4079-bacd-05d1f0212a5b"
      },
      "source": [
        "ann.fit(X_train, y_train, batch_size = 64, epochs = 200, verbose = 1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 2s 2s/step - loss: 13362653184.0000 - mean_absolute_error: 108583.0234\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 13263295488.0000 - mean_absolute_error: 108174.2266\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13165211648.0000 - mean_absolute_error: 107768.8984\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 13067611136.0000 - mean_absolute_error: 107364.3750\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12970049536.0000 - mean_absolute_error: 106958.1250\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12872078336.0000 - mean_absolute_error: 106548.8516\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 12774085632.0000 - mean_absolute_error: 106138.0156\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 12676163584.0000 - mean_absolute_error: 105725.6641\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12578615296.0000 - mean_absolute_error: 105313.0625\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12482021376.0000 - mean_absolute_error: 104902.5469\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12385626112.0000 - mean_absolute_error: 104490.9453\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12289773568.0000 - mean_absolute_error: 104080.1719\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12195268608.0000 - mean_absolute_error: 103673.3594\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12101499904.0000 - mean_absolute_error: 103267.9844\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12009226240.0000 - mean_absolute_error: 102867.7344\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11917370368.0000 - mean_absolute_error: 102468.2031\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11825710080.0000 - mean_absolute_error: 102067.9766\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 11735144448.0000 - mean_absolute_error: 101670.1016\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11646323712.0000 - mean_absolute_error: 101276.1406\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11557779456.0000 - mean_absolute_error: 100880.8984\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11469084672.0000 - mean_absolute_error: 100483.2422\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11380620288.0000 - mean_absolute_error: 100084.2578\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11292754944.0000 - mean_absolute_error: 99686.0000\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11206363136.0000 - mean_absolute_error: 99291.0938\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11120957440.0000 - mean_absolute_error: 98897.2344\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11035165696.0000 - mean_absolute_error: 98500.4844\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10949206016.0000 - mean_absolute_error: 98103.1719\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10862834688.0000 - mean_absolute_error: 97703.5547\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10775332864.0000 - mean_absolute_error: 97297.3672\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10687780864.0000 - mean_absolute_error: 96888.6641\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10599480320.0000 - mean_absolute_error: 96474.3750\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10510624768.0000 - mean_absolute_error: 96055.0625\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10421240832.0000 - mean_absolute_error: 95631.2500\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10331950080.0000 - mean_absolute_error: 95205.6250\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 10242758656.0000 - mean_absolute_error: 94778.4844\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10153445376.0000 - mean_absolute_error: 94349.2344\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 10063849472.0000 - mean_absolute_error: 93917.1250\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9973969920.0000 - mean_absolute_error: 93481.3906\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9884065792.0000 - mean_absolute_error: 93043.3984\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9794115584.0000 - mean_absolute_error: 92602.7969\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9703810048.0000 - mean_absolute_error: 92158.1719\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9612955648.0000 - mean_absolute_error: 91708.4141\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9521369088.0000 - mean_absolute_error: 91252.5234\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 9429309440.0000 - mean_absolute_error: 90791.6016\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9336764416.0000 - mean_absolute_error: 90325.8984\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 9243710464.0000 - mean_absolute_error: 89855.1016\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9150294016.0000 - mean_absolute_error: 89380.2500\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9056114688.0000 - mean_absolute_error: 88898.5547\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8961005568.0000 - mean_absolute_error: 88408.7969\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8865155072.0000 - mean_absolute_error: 87911.8516\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8768675840.0000 - mean_absolute_error: 87408.5859\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8671477760.0000 - mean_absolute_error: 86898.7109\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8573791232.0000 - mean_absolute_error: 86383.4844\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8475424256.0000 - mean_absolute_error: 85861.8125\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8376390656.0000 - mean_absolute_error: 85334.0000\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8276612096.0000 - mean_absolute_error: 84798.9609\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8175675904.0000 - mean_absolute_error: 84254.4219\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8073863168.0000 - mean_absolute_error: 83702.1406\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7970929152.0000 - mean_absolute_error: 83140.4219\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7866888192.0000 - mean_absolute_error: 82574.3828\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7761893888.0000 - mean_absolute_error: 82011.5781\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7656372736.0000 - mean_absolute_error: 81441.8125\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7550073344.0000 - mean_absolute_error: 80864.0391\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7443102208.0000 - mean_absolute_error: 80278.4062\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7335337984.0000 - mean_absolute_error: 79683.8281\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7226825216.0000 - mean_absolute_error: 79080.1406\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7117204480.0000 - mean_absolute_error: 78465.4219\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7006389760.0000 - mean_absolute_error: 77837.8984\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6894495232.0000 - mean_absolute_error: 77198.5156\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6781595648.0000 - mean_absolute_error: 76547.7266\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6667265024.0000 - mean_absolute_error: 75883.1875\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6550915584.0000 - mean_absolute_error: 75200.9375\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6431510528.0000 - mean_absolute_error: 74493.5156\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6308831232.0000 - mean_absolute_error: 73760.1094\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6182539776.0000 - mean_absolute_error: 72998.2500\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6052539392.0000 - mean_absolute_error: 72202.1016\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5918012416.0000 - mean_absolute_error: 71372.6094\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5776973824.0000 - mean_absolute_error: 70498.1406\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5633430528.0000 - mean_absolute_error: 69596.8750\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5488458240.0000 - mean_absolute_error: 68674.0156\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5342103040.0000 - mean_absolute_error: 67728.5234\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5194629120.0000 - mean_absolute_error: 66760.7891\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5046749184.0000 - mean_absolute_error: 65817.6875\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4898724352.0000 - mean_absolute_error: 64871.2500\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4750853632.0000 - mean_absolute_error: 63910.0117\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4603397120.0000 - mean_absolute_error: 62934.5742\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4456694784.0000 - mean_absolute_error: 61945.9375\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4311120384.0000 - mean_absolute_error: 60945.4688\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4166790400.0000 - mean_absolute_error: 59933.2500\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4023616000.0000 - mean_absolute_error: 58908.0117\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3882281728.0000 - mean_absolute_error: 57874.0000\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3742616064.0000 - mean_absolute_error: 56830.3203\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3605044736.0000 - mean_absolute_error: 55778.9297\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3469595904.0000 - mean_absolute_error: 54719.8359\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3336030208.0000 - mean_absolute_error: 53651.1992\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3204507648.0000 - mean_absolute_error: 52573.5938\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3075286272.0000 - mean_absolute_error: 51488.2031\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2948365568.0000 - mean_absolute_error: 50394.6602\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2823910144.0000 - mean_absolute_error: 49293.4531\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2702074624.0000 - mean_absolute_error: 48185.5508\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2583036928.0000 - mean_absolute_error: 47071.9102\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2466814720.0000 - mean_absolute_error: 45952.4727\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2353447936.0000 - mean_absolute_error: 44862.7422\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2243278080.0000 - mean_absolute_error: 43770.2188\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2136374656.0000 - mean_absolute_error: 42675.9023\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2032771328.0000 - mean_absolute_error: 41579.5234\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1932340992.0000 - mean_absolute_error: 40479.6875\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1835326080.0000 - mean_absolute_error: 39377.8945\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1741951232.0000 - mean_absolute_error: 38276.4961\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1652220928.0000 - mean_absolute_error: 37175.7383\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1566108928.0000 - mean_absolute_error: 36075.5938\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1483618688.0000 - mean_absolute_error: 34976.2500\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1404770560.0000 - mean_absolute_error: 33877.9062\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1329628928.0000 - mean_absolute_error: 32781.4922\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1258200960.0000 - mean_absolute_error: 31687.9121\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1190372736.0000 - mean_absolute_error: 30595.7188\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1126375680.0000 - mean_absolute_error: 29508.7441\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1065990528.0000 - mean_absolute_error: 28453.9629\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1009366912.0000 - mean_absolute_error: 27453.7559\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 956274496.0000 - mean_absolute_error: 26457.0000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 906959872.0000 - mean_absolute_error: 25469.7461\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 861400256.0000 - mean_absolute_error: 24493.7363\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 819652032.0000 - mean_absolute_error: 23601.0098\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 781537728.0000 - mean_absolute_error: 22778.2676\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 747093824.0000 - mean_absolute_error: 22075.7383\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 716174272.0000 - mean_absolute_error: 21427.4492\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 688561792.0000 - mean_absolute_error: 20819.5527\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 664190336.0000 - mean_absolute_error: 20227.5781\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 642892032.0000 - mean_absolute_error: 19710.2617\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 624626816.0000 - mean_absolute_error: 19378.5156\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 608963008.0000 - mean_absolute_error: 19068.4941\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 595675264.0000 - mean_absolute_error: 18768.9199\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 584596608.0000 - mean_absolute_error: 18482.6035\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 575470272.0000 - mean_absolute_error: 18209.5215\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 567986176.0000 - mean_absolute_error: 17948.6133\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 561942336.0000 - mean_absolute_error: 17711.9961\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 557081792.0000 - mean_absolute_error: 17516.3418\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 553158592.0000 - mean_absolute_error: 17338.3750\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 549982272.0000 - mean_absolute_error: 17193.5586\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 547368832.0000 - mean_absolute_error: 17057.6328\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 545119936.0000 - mean_absolute_error: 16929.2598\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 543094976.0000 - mean_absolute_error: 16808.7461\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 541187008.0000 - mean_absolute_error: 16698.5566\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 539296448.0000 - mean_absolute_error: 16603.2598\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 537317376.0000 - mean_absolute_error: 16512.3477\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 535230624.0000 - mean_absolute_error: 16434.3926\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 533032032.0000 - mean_absolute_error: 16362.8594\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 530683072.0000 - mean_absolute_error: 16296.2783\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 528181664.0000 - mean_absolute_error: 16234.6074\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 525535328.0000 - mean_absolute_error: 16176.1465\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 522753024.0000 - mean_absolute_error: 16124.5205\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 519750848.0000 - mean_absolute_error: 16073.2217\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 516574304.0000 - mean_absolute_error: 16023.0098\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 513285472.0000 - mean_absolute_error: 15977.7266\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 509916992.0000 - mean_absolute_error: 15935.1533\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 506487648.0000 - mean_absolute_error: 15897.8594\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 503090176.0000 - mean_absolute_error: 15868.6279\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 499682560.0000 - mean_absolute_error: 15840.4980\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 496280768.0000 - mean_absolute_error: 15813.3301\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 492898880.0000 - mean_absolute_error: 15786.5918\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 489559744.0000 - mean_absolute_error: 15761.8750\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 486275520.0000 - mean_absolute_error: 15737.3232\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 483045984.0000 - mean_absolute_error: 15711.9658\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 479865024.0000 - mean_absolute_error: 15684.2441\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 476702048.0000 - mean_absolute_error: 15653.7314\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 473581504.0000 - mean_absolute_error: 15622.3223\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 470521344.0000 - mean_absolute_error: 15589.2441\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 467489280.0000 - mean_absolute_error: 15552.6982\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 464576832.0000 - mean_absolute_error: 15515.9746\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 461881504.0000 - mean_absolute_error: 15482.6270\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 459254464.0000 - mean_absolute_error: 15447.4688\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 456681536.0000 - mean_absolute_error: 15411.4404\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 454113696.0000 - mean_absolute_error: 15373.6748\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 451557696.0000 - mean_absolute_error: 15333.4043\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 449063328.0000 - mean_absolute_error: 15294.0488\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 446591936.0000 - mean_absolute_error: 15252.5264\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 444131232.0000 - mean_absolute_error: 15208.1973\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 441713760.0000 - mean_absolute_error: 15163.1465\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 439285760.0000 - mean_absolute_error: 15115.2080\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 436866560.0000 - mean_absolute_error: 15067.5029\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 434504192.0000 - mean_absolute_error: 15023.5938\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 432188768.0000 - mean_absolute_error: 14979.9717\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 429893024.0000 - mean_absolute_error: 14937.8965\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 427754944.0000 - mean_absolute_error: 14897.1953\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 425746720.0000 - mean_absolute_error: 14857.2061\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 423743584.0000 - mean_absolute_error: 14816.8750\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 421759008.0000 - mean_absolute_error: 14776.7529\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 419817696.0000 - mean_absolute_error: 14738.1201\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 417897792.0000 - mean_absolute_error: 14700.2109\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 415977952.0000 - mean_absolute_error: 14662.1436\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 414093952.0000 - mean_absolute_error: 14624.7402\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 412218688.0000 - mean_absolute_error: 14587.2676\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 410371648.0000 - mean_absolute_error: 14550.2812\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 408548608.0000 - mean_absolute_error: 14514.1270\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 406748160.0000 - mean_absolute_error: 14478.7783\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 404960704.0000 - mean_absolute_error: 14443.2188\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 403184256.0000 - mean_absolute_error: 14408.1689\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 401417728.0000 - mean_absolute_error: 14373.4629\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 399660960.0000 - mean_absolute_error: 14339.0527\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 397914848.0000 - mean_absolute_error: 14304.8955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79a66b3238b0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H0zKKNEBLD5"
      },
      "source": [
        "### Predicting the results of the Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA0yApEmBG1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d0f45b-e29f-4b89-9071-1c15fa32d0e9"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "np.set_printoptions(precision=2)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 149ms/step\n",
            "[[105885.77 103282.48]\n",
            " [115638.3  144259.5 ]\n",
            " [114132.55 146122.05]\n",
            " [ 69104.4   77798.93]\n",
            " [184046.09 191050.49]\n",
            " [149073.08 105008.41]\n",
            " [ 75114.34  81229.16]\n",
            " [ 89047.55  97483.66]\n",
            " [129669.66 110352.35]\n",
            " [165903.33 166188.04]]\n"
          ]
        }
      ]
    }
  ]
}